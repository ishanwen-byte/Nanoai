//! # NanoAI - è½»é‡çº§ LLM å®¢æˆ·ç«¯åº“
//!
//! NanoAI æ˜¯ä¸€ä¸ªä¸“ä¸º OpenRouter API è®¾è®¡çš„è½»é‡çº§ Rust å®¢æˆ·ç«¯åº“ï¼Œ
//! æä¾›ç®€æ´çš„æ¥å£æ¥ä¸å„ç§å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚
//!
//! ## ä¸»è¦ç‰¹æ€§
//!
//! - ğŸš€ å¼‚æ­¥æ”¯æŒï¼šåŸºäº tokio çš„å®Œå…¨å¼‚æ­¥å®ç°
//! - ğŸ”„ æµå¼å“åº”ï¼šæ”¯æŒå®æ—¶æµå¼æ–‡æœ¬ç”Ÿæˆ
//! - ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼šè¯¦ç»†çš„è¯·æ±‚ç»Ÿè®¡å’Œæ€§èƒ½ç›‘æ§
//! - ğŸ”§ çµæ´»é…ç½®ï¼šæ”¯æŒç¯å¢ƒå˜é‡å’Œ Builder æ¨¡å¼é…ç½®
//! - ğŸ›¡ï¸ é”™è¯¯å¤„ç†ï¼šå®Œå–„çš„é”™è¯¯ç±»å‹å’Œé‡è¯•æœºåˆ¶
//! - ğŸ¯ å‡½æ•°å¼è®¾è®¡ï¼šéµå¾ª Rust å‡½æ•°å¼ç¼–ç¨‹æœ€ä½³å®è·µ
//!
//! ## å¿«é€Ÿå¼€å§‹
//!
//! ```rust
//! use nanoai::{Config, LLMClient};
//!
//! #[tokio::main]
//! async fn main() -> nanoai::Result<()> {
//!     let config = Config::from_env()?;
//!     let client = LLMClient::new(config);
//!     
//!     let response = client.generate("Hello, world!").await?;
//!     println!("Response: {}", response);
//!     
//!     Ok(())
//! }
//! ```

use futures::{Stream, StreamExt};
use log::{debug, error, info, warn};
use nanorand::{Rng, WyRand};
use reqwest::{
    Client as ReqwestClient,
    header::{HeaderMap, HeaderName, HeaderValue},
};
use serde::{Deserialize, Serialize};
use serde_json::Value;
use std::time::{Duration, Instant};
use thiserror::Error;
use tokio::time::sleep;

// ================================================================================================
// é”™è¯¯å¤„ç†æ¨¡å—
// ================================================================================================

/// NanoAI åº“çš„ç»Ÿä¸€é”™è¯¯ç±»å‹
/// 
/// æä¾›äº†å®Œæ•´çš„é”™è¯¯åˆ†ç±»ï¼Œä¾¿äºä¸Šå±‚åº”ç”¨è¿›è¡Œç²¾ç¡®çš„é”™è¯¯å¤„ç†
#[derive(Debug, Error)]
pub enum NanoError {
    /// HTTP è¯·æ±‚ç›¸å…³é”™è¯¯
    #[error("HTTPè¯·æ±‚å¤±è´¥: {0}")]
    Http(#[from] reqwest::Error),
    
    /// JSON åºåˆ—åŒ–/ååºåˆ—åŒ–é”™è¯¯
    #[error("JSONå¤„ç†é”™è¯¯: {0}")]
    Json(#[from] serde_json::Error),
    
    /// API æœåŠ¡ç«¯é”™è¯¯
    #[error("APIé”™è¯¯: {0}")]
    Api(String),
    
    /// è¯·æ±‚è¶…æ—¶é”™è¯¯
    #[error("è¯·æ±‚è¶…æ—¶")]
    Timeout,
    
    /// å“åº”å†…å®¹ä¸ºç©º
    #[error("å“åº”å†…å®¹ä¸ºç©º")]
    NoContent,
    
    /// æµå¤„ç†ç›¸å…³é”™è¯¯
    #[error("æµå¤„ç†é”™è¯¯: {0}")]
    StreamError(String),
    
    /// API è¯·æ±‚é¢‘ç‡é™åˆ¶
    #[error("è¯·æ±‚é¢‘ç‡è¶…é™: {0}")]
    RateLimit(String),
    
    /// èº«ä»½éªŒè¯å¤±è´¥
    #[error("èº«ä»½éªŒè¯å¤±è´¥: {0}")]
    Auth(String),
    
    /// æŒ‡å®šçš„æ¨¡å‹ä¸å­˜åœ¨
    #[error("æ¨¡å‹ä¸å­˜åœ¨: {0}")]
    ModelNotFound(String),
    
    /// è¯·æ±‚å‚æ•°æ— æ•ˆ
    #[error("è¯·æ±‚å‚æ•°æ— æ•ˆ: {0}")]
    InvalidRequest(String),
    
    /// é…ç½®ç›¸å…³é”™è¯¯
    #[error("é…ç½®é”™è¯¯: {0}")]
    Config(String),
}

/// åº“çš„ç»Ÿä¸€ Result ç±»å‹
pub type Result<T> = std::result::Result<T, NanoError>;

// ================================================================================================
// æ•°æ®ç»“æ„æ¨¡å—
// ================================================================================================

/// èŠå¤©æ¶ˆæ¯ç»“æ„
/// 
/// è¡¨ç¤ºå¯¹è¯ä¸­çš„å•æ¡æ¶ˆæ¯ï¼ŒåŒ…å«è§’è‰²å’Œå†…å®¹ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize, Hash, PartialEq, Eq)]
pub struct Message {
    /// æ¶ˆæ¯è§’è‰²ï¼š"system", "user", "assistant"
    pub role: String,
    /// æ¶ˆæ¯å†…å®¹
    pub content: String,
}

/// è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯
/// 
/// è®°å½• API è¯·æ±‚çš„è¯¦ç»†ç»Ÿè®¡æ•°æ®ï¼Œç”¨äºæ€§èƒ½ç›‘æ§å’Œåˆ†æ
#[derive(Debug, Clone, Default)]
pub struct RequestStats {
    /// è¯·æ±‚è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    pub duration_ms: u64,
    /// è¾“å…¥ token æ•°é‡
    pub prompt_tokens: Option<u32>,
    /// è¾“å‡º token æ•°é‡
    pub completion_tokens: Option<u32>,
    /// æ€» token æ•°é‡
    pub total_tokens: Option<u32>,
    /// ä½¿ç”¨çš„æ¨¡å‹åç§°
    pub model: String,
    /// è¯·æ±‚æ—¶é—´æˆ³
    pub timestamp: Option<std::time::SystemTime>,
}

/// å¸¦ç»Ÿè®¡ä¿¡æ¯çš„å“åº”ç»“æœ
/// 
/// åŒ…å«ç”Ÿæˆçš„å†…å®¹å’Œè¯¦ç»†çš„è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug)]
pub struct ResponseWithStats {
    /// ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
    pub content: String,
    /// è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯
    pub stats: RequestStats,
}

// ================================================================================================
// é…ç½®æ¨¡å—
// ================================================================================================

/// LLM å®¢æˆ·ç«¯é…ç½®
/// 
/// åŒ…å«æ‰€æœ‰å¿…è¦çš„é…ç½®å‚æ•°ï¼Œæ”¯æŒ Builder æ¨¡å¼å’Œç¯å¢ƒå˜é‡é…ç½®
#[derive(Debug, Clone)]
pub struct Config {
    /// æ¨¡å‹åç§°
    model: String,
    /// ç³»ç»Ÿæ¶ˆæ¯
    system_message: String,
    /// æ¸©åº¦å‚æ•° (0.0-2.0)
    temperature: f32,
    /// Top-p å‚æ•° (0.0-1.0)
    top_p: f32,
    /// æœ€å¤§ç”Ÿæˆ token æ•°
    max_tokens: u32,
    /// è¯·æ±‚è¶…æ—¶æ—¶é—´
    timeout: Duration,
    /// é‡è¯•æ¬¡æ•°
    retries: usize,
    /// é‡è¯•é—´éš”
    retry_delay: Duration,
    /// API åŸºç¡€ URL
    api_base: String,
    /// API å¯†é’¥
    api_key: String,
    /// éšæœºç§å­
    random_seed: Option<u64>,
}

impl Default for Config {
    /// åˆ›å»ºé»˜è®¤é…ç½®
    /// 
    /// ä½¿ç”¨ DeepSeek å…è´¹æ¨¡å‹ä½œä¸ºé»˜è®¤é€‰æ‹©
    fn default() -> Self {
        Self {
            model: "tngtech/deepseek-r1t2-chimera:free".into(),
            system_message: "You are a helpful AI assistant.".into(),
            temperature: 0.7,
            top_p: 1.0,
            max_tokens: 4096,
            timeout: Duration::from_secs(60),
            retries: 3,
            retry_delay: Duration::from_millis(1000),
            api_base: "https://openrouter.ai/api/v1".into(),
            api_key: String::new(),
            random_seed: None,
        }
    }
}

/// ç”Ÿæˆ Config Builder æ–¹æ³•çš„å®
/// 
/// è‡ªåŠ¨ç”Ÿæˆ `with_field_name` å½¢å¼çš„ builder æ–¹æ³•
macro_rules! config_builder {
    ($field:ident, $type:ty) => {
        paste::paste! {
            /// è®¾ç½®é…ç½®å­—æ®µ
            pub fn [<with_ $field>](self, $field: $type) -> Self {
                Self { $field, ..self }
            }
        }
    };
    ($field:ident, $type:ty, $transform:expr) => {
        paste::paste! {
            /// è®¾ç½®é…ç½®å­—æ®µï¼ˆå¸¦è½¬æ¢ï¼‰
            pub fn [<with_ $field>](self, $field: $type) -> Self {
                Self { $field: $transform($field), ..self }
            }
        }
    };
}

impl Config {
    /// ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®
    /// 
    /// è‡ªåŠ¨è¯»å– .env æ–‡ä»¶å’Œç¯å¢ƒå˜é‡ï¼š
    /// - `OPENROUTER_API_KEY` æˆ– `API_KEY`ï¼šAPI å¯†é’¥
    /// - `OPENROUTER_MODEL` æˆ– `MODEL`ï¼šæ¨¡å‹åç§°
    pub fn from_env() -> Result<Self> {
        // å°è¯•åŠ è½½ .env æ–‡ä»¶
        if std::path::Path::new(".env").exists() {
            if let Ok(content) = std::fs::read_to_string(".env") {
                content
                    .lines()
                    .filter_map(|line| line.split_once('='))
                    .for_each(|(key, value)| {
                        let key = key.trim();
                        let value = value.trim().trim_matches('"').trim_matches('\'');
                        unsafe {
                            std::env::set_var(key, value);
                        }
                    });
            }
        }

        let api_key = std::env::var("OPENROUTER_API_KEY")
            .or_else(|_| std::env::var("API_KEY"))
            .map_err(|_| {
                NanoError::Config(
                    "No OpenRouter API key found in environment variables".to_string(),
                )
            })?;

        let model = std::env::var("OPENROUTER_MODEL")
            .or_else(|_| std::env::var("MODEL"))
            .unwrap_or_else(|_| "tngtech/deepseek-r1t2-chimera:free".to_string());

        Ok(Self::default().with_api_key(api_key).with_model(model))
    }

    // ä½¿ç”¨å®ç”Ÿæˆ builder æ–¹æ³•
    config_builder!(api_base, String);
    config_builder!(model, String);
    config_builder!(api_key, String);
    config_builder!(temperature, f32);
    config_builder!(top_p, f32);
    config_builder!(max_tokens, u32);
    config_builder!(random_seed, u64, Some);

    /// è‡ªåŠ¨ç”Ÿæˆéšæœºç§å­
    /// 
    /// ä½¿ç”¨é«˜æ€§èƒ½çš„ WyRand ç®—æ³•ç”Ÿæˆéšæœºç§å­
    pub fn with_random_seed_auto(self) -> Self {
        let mut rng = WyRand::new();
        Self {
            random_seed: Some(rng.generate::<u64>()),
            ..self
        }
    }
}

// ================================================================================================
// API å“åº”ç»“æ„æ¨¡å—
// ================================================================================================

/// API å®Œæ•´å“åº”ç»“æ„
#[derive(Debug, Deserialize)]
#[allow(dead_code)]
struct CompletionResponse {
    choices: Vec<CompletionChoice>,
    usage: Option<Usage>,
    model: Option<String>,
}

/// API å“åº”é€‰æ‹©é¡¹
#[derive(Debug, Deserialize)]
#[allow(dead_code)]
struct CompletionChoice {
    message: CompletionMessage,
    finish_reason: Option<String>,
}

/// API å“åº”æ¶ˆæ¯
#[derive(Debug, Deserialize)]
#[allow(dead_code)]
struct CompletionMessage {
    content: String,
    role: Option<String>,
}

/// API ä½¿ç”¨ç»Ÿè®¡
#[derive(Debug, Deserialize)]
struct Usage {
    prompt_tokens: u32,
    completion_tokens: u32,
    total_tokens: u32,
}

/// æµå¼å“åº”ç»“æ„
#[derive(Debug, Deserialize)]
struct StreamResponse {
    choices: Vec<StreamChoice>,
    #[allow(dead_code)]
    model: Option<String>,
    #[allow(dead_code)]
    usage: Option<Usage>,
}

/// æµå¼å“åº”é€‰æ‹©é¡¹
#[derive(Debug, Deserialize)]
struct StreamChoice {
    delta: StreamDelta,
    #[allow(dead_code)]
    finish_reason: Option<String>,
    #[allow(dead_code)]
    index: Option<u32>,
}

/// æµå¼å“åº”å¢é‡æ•°æ®
#[derive(Debug, Deserialize)]
struct StreamDelta {
    content: Option<String>,
    #[allow(dead_code)]
    role: Option<String>,
}

// ================================================================================================
// æ ¸å¿ƒå®¢æˆ·ç«¯æ¨¡å—
// ================================================================================================

/// LLM å®¢æˆ·ç«¯
/// 
/// æä¾›ä¸ OpenRouter API äº¤äº’çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œæ”¯æŒåŒæ­¥å’Œæµå¼è¯·æ±‚
#[derive(Debug, Clone)]
pub struct LLMClient {
    /// HTTP å®¢æˆ·ç«¯
    client: ReqwestClient,
    /// å®¢æˆ·ç«¯é…ç½®
    config: Config,
    /// HTTP è¯·æ±‚å¤´
    headers: HeaderMap,
}

impl LLMClient {
    /// åˆ›å»ºæ–°çš„ LLM å®¢æˆ·ç«¯
    /// 
    /// # å‚æ•°
    /// 
    /// * `config` - å®¢æˆ·ç«¯é…ç½®
    /// 
    /// # ç¤ºä¾‹
    /// 
    /// ```rust
    /// use nanoai::{Config, LLMClient};
    /// 
    /// let config = Config::default().with_api_key("your-api-key".to_string());
    /// let client = LLMClient::new(config);
    /// ```
    pub fn new(config: Config) -> Self {
        static INITIALIZED: std::sync::OnceLock<std::sync::Mutex<Vec<String>>> =
            std::sync::OnceLock::new();

        let models_mutex = INITIALIZED.get_or_init(|| std::sync::Mutex::new(Vec::new()));
        if let Ok(mut models) = models_mutex.lock()
            && !models.contains(&config.model)
        {
            info!("Initialized LLM with model: {}", config.model);
            models.push(config.model.clone());
        }

        let headers = build_headers(&config.api_key);

        Self {
            client: ReqwestClient::builder()
                .timeout(config.timeout)
                .connect_timeout(Duration::from_secs(10))
                .build()
                .unwrap_or_else(|_| ReqwestClient::new()),
            config,
            headers,
        }
    }

    /// ç”Ÿæˆæ–‡æœ¬å“åº”
    /// 
    /// æœ€ç®€å•çš„æ–‡æœ¬ç”Ÿæˆæ¥å£ï¼Œä½¿ç”¨é»˜è®¤ç³»ç»Ÿæ¶ˆæ¯
    /// 
    /// # å‚æ•°
    /// 
    /// * `prompt` - ç”¨æˆ·è¾“å…¥æç¤º
    /// 
    /// # è¿”å›
    /// 
    /// ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
    pub async fn generate(&self, prompt: &str) -> Result<String> {
        self.generate_with_stats(prompt)
            .await
            .map(|response| response.content)
    }

    /// ç”Ÿæˆæ–‡æœ¬å“åº”ï¼ˆå¸¦ç»Ÿè®¡ä¿¡æ¯ï¼‰
    /// 
    /// # å‚æ•°
    /// 
    /// * `prompt` - ç”¨æˆ·è¾“å…¥æç¤º
    /// 
    /// # è¿”å›
    /// 
    /// åŒ…å«ç”Ÿæˆå†…å®¹å’Œç»Ÿè®¡ä¿¡æ¯çš„å“åº”
    pub async fn generate_with_stats(&self, prompt: &str) -> Result<ResponseWithStats> {
        let user_message = Message {
            role: "user".to_string(),
            content: prompt.to_string(),
        };
        
        self.generate_with_context_stats(&self.config.system_message, &[user_message])
            .await
    }

    /// ä½¿ç”¨ä¸Šä¸‹æ–‡ç”Ÿæˆæ–‡æœ¬å“åº”ï¼ˆå¸¦ç»Ÿè®¡ä¿¡æ¯ï¼‰
    /// 
    /// # å‚æ•°
    /// 
    /// * `system_msg` - ç³»ç»Ÿæ¶ˆæ¯
    /// * `messages` - å¯¹è¯å†å²æ¶ˆæ¯
    /// 
    /// # è¿”å›
    /// 
    /// åŒ…å«ç”Ÿæˆå†…å®¹å’Œç»Ÿè®¡ä¿¡æ¯çš„å“åº”
    pub async fn generate_with_context_stats(
        &self,
        system_msg: &str,
        messages: &[Message],
    ) -> Result<ResponseWithStats> {
        let start_time = Instant::now();
        let prepared_messages = prepare_messages(system_msg, messages)?;
        let params = build_params(&self.config, prepared_messages);
        let response = self.call_api_with_stats(params).await?;
        let duration = start_time.elapsed();

        Ok(ResponseWithStats {
            content: response.content,
            stats: RequestStats {
                duration_ms: duration.as_millis() as u64,
                prompt_tokens: response.stats.prompt_tokens,
                completion_tokens: response.stats.completion_tokens,
                total_tokens: response.stats.total_tokens,
                model: self.config.model.clone(),
                timestamp: Some(std::time::SystemTime::now()),
            },
        })
    }

    /// ä½¿ç”¨ä¸Šä¸‹æ–‡ç”Ÿæˆæ–‡æœ¬å“åº”
    /// 
    /// # å‚æ•°
    /// 
    /// * `system_msg` - ç³»ç»Ÿæ¶ˆæ¯
    /// * `messages` - å¯¹è¯å†å²æ¶ˆæ¯
    /// 
    /// # è¿”å›
    /// 
    /// ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
    pub async fn generate_with_context(
        &self,
        system_msg: &str,
        messages: &[Message],
    ) -> Result<String> {
        let prepared_messages = prepare_messages(system_msg, messages)?;
        let params = build_params(&self.config, prepared_messages);
        self.call_with_retry(&params).await
    }

    /// ç”Ÿæˆæµå¼æ–‡æœ¬å“åº”
    /// 
    /// è¿”å›ä¸€ä¸ªå¼‚æ­¥æµï¼Œå¯ä»¥å®æ—¶æ¥æ”¶ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ
    /// 
    /// # å‚æ•°
    /// 
    /// * `prompt` - ç”¨æˆ·è¾“å…¥æç¤º
    /// 
    /// # è¿”å›
    /// 
    /// æ–‡æœ¬ç‰‡æ®µçš„å¼‚æ­¥æµ
    pub async fn generate_stream(
        &self,
        prompt: &str,
    ) -> Result<impl Stream<Item = Result<String>> + '_> {
        let user_msg = message("user", prompt);
        let messages = prepare_messages(&self.config.system_message, &[user_msg])?;
        self.create_stream(messages).await
    }

    /// ä½¿ç”¨ä¸Šä¸‹æ–‡ç”Ÿæˆæµå¼æ–‡æœ¬å“åº”
    /// 
    /// # å‚æ•°
    /// 
    /// * `system_msg` - ç³»ç»Ÿæ¶ˆæ¯
    /// * `messages` - å¯¹è¯å†å²æ¶ˆæ¯
    /// 
    /// # è¿”å›
    /// 
    /// æ–‡æœ¬ç‰‡æ®µçš„å¼‚æ­¥æµ
    pub async fn generate_stream_with_context(
        &self,
        system_msg: &str,
        messages: &[Message],
    ) -> Result<impl Stream<Item = Result<String>> + '_> {
        let all_messages = prepare_messages(system_msg, messages)?;
        self.create_stream(all_messages).await
    }

    /// åˆ›å»ºæµå¼å“åº”
    /// 
    /// å†…éƒ¨æ–¹æ³•ï¼Œå¤„ç†æµå¼å“åº”çš„åˆ›å»ºå’Œæ•°æ®å¤„ç†
    async fn create_stream(
        &self,
        messages: Vec<Message>,
    ) -> Result<impl Stream<Item = Result<String>> + '_> {
        let params = build_params_stream(&self.config, &messages)?;
        let response = self.send_request(&params).await?;
        let response = check_response_status(response).await?;

        use futures::future;
        Ok(response
            .bytes_stream()
            .map(|chunk_result| {
                chunk_result
                    .map_err(|e| NanoError::StreamError(e.to_string()))
                    .and_then(|chunk| {
                        std::str::from_utf8(&chunk)
                            .map_err(|e| NanoError::StreamError(format!("Invalid UTF-8: {e}")))
                            .and_then(process_stream_chunk)
                    })
            })
            .filter(|result| {
                future::ready(match result {
                    Ok(s) => !s.is_empty(),
                    Err(_) => true,
                })
            }))
    }

    /// å¸¦é‡è¯•æœºåˆ¶çš„ API è°ƒç”¨
    /// 
    /// æ ¹æ®é…ç½®çš„é‡è¯•æ¬¡æ•°å’Œå»¶è¿Ÿè¿›è¡Œè‡ªåŠ¨é‡è¯•
    async fn call_with_retry(&self, params: &Value) -> Result<String> {
        let mut retries_left = self.config.retries;
        
        loop {
            match self.call_api(params).await {
                Ok(result) => return Ok(result),
                Err(e) => {
                    if retries_left > 0 {
                        warn!(
                            "Request failed: {e}. Retrying in {:?}...",
                            self.config.retry_delay
                        );
                        sleep(self.config.retry_delay).await;
                        retries_left -= 1;
                    } else {
                        error!("All {} retries exhausted: {e}", self.config.retries);
                        return Err(e);
                    }
                }
            }
        }
    }

    /// å‘é€ HTTP è¯·æ±‚
    /// 
    /// å†…éƒ¨æ–¹æ³•ï¼Œå¤„ç†å®é™…çš„ HTTP è¯·æ±‚å‘é€
    async fn send_request(&self, params: &Value) -> Result<reqwest::Response> {
        let endpoint = format!("{}/chat/completions", self.config.api_base);

        self.client
            .post(&endpoint)
            .headers(self.headers.clone())
            .json(params)
            .timeout(self.config.timeout)
            .send()
            .await
            .map_err(|e| {
                if e.is_timeout() {
                    NanoError::Timeout
                } else {
                    e.into()
                }
            })
    }

    /// è°ƒç”¨ APIï¼ˆä»…è¿”å›å†…å®¹ï¼‰
    async fn call_api(&self, params: &Value) -> Result<String> {
        debug!("API parameters: {params:?}");
        let response = self.send_request(params).await?;
        handle_response(response).await
    }

    /// è°ƒç”¨ APIï¼ˆè¿”å›å†…å®¹å’Œç»Ÿè®¡ä¿¡æ¯ï¼‰
    async fn call_api_with_stats(&self, params: Value) -> Result<ResponseWithStats> {
        let response = self.send_request(&params).await?;
        handle_response_with_stats(response).await
    }
}

// ================================================================================================
// å·¥å…·å‡½æ•°æ¨¡å—
// ================================================================================================

/// å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
/// 
/// å°†ç³»ç»Ÿæ¶ˆæ¯å’Œç”¨æˆ·æ¶ˆæ¯åˆå¹¶ä¸ºå®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨
/// 
/// # å‚æ•°
/// 
/// * `system_msg` - ç³»ç»Ÿæ¶ˆæ¯å†…å®¹
/// * `messages` - ç”¨æˆ·æ¶ˆæ¯åˆ—è¡¨
/// 
/// # è¿”å›
/// 
/// åŒ…å«ç³»ç»Ÿæ¶ˆæ¯çš„å®Œæ•´æ¶ˆæ¯åˆ—è¡¨
fn prepare_messages(system_msg: &str, messages: &[Message]) -> Result<Vec<Message>> {
    let system_message = Message {
        role: "system".into(),
        content: system_msg.into(),
    };
    
    Ok([system_message]
        .into_iter()
        .chain(messages.iter().cloned())
        .collect())
}

/// æ„å»ºç»Ÿä¸€çš„ API å‚æ•°
/// 
/// æ ¹æ®é…ç½®å’Œæ¶ˆæ¯æ„å»º API è¯·æ±‚å‚æ•°
fn build_params_unified<T>(config: &Config, messages: T, stream: bool) -> Value
where
    T: Into<Vec<Message>>,
{
    let mut params = serde_json::json!({
        "model": config.model,
        "messages": messages.into(),
        "stream": stream,
        "temperature": config.temperature,
        "top_p": config.top_p,
        "max_tokens": config.max_tokens,
    });

    if let Some(seed) = config.random_seed {
        params["seed"] = seed.into();
    }

    params
}

/// æ„å»ºéæµå¼ API å‚æ•°
fn build_params(config: &Config, messages: Vec<Message>) -> Value {
    build_params_unified(config, messages, false)
}

/// æ„å»ºæµå¼ API å‚æ•°
fn build_params_stream(config: &Config, messages: &[Message]) -> Result<Value> {
    Ok(build_params_unified(config, messages.to_vec(), true))
}

/// æ„å»º HTTP è¯·æ±‚å¤´
/// 
/// åˆ›å»ºåŒ…å«è®¤è¯å’Œå†…å®¹ç±»å‹çš„ HTTP å¤´
/// 
/// # å‚æ•°
/// 
/// * `api_key` - API å¯†é’¥
/// 
/// # è¿”å›
/// 
/// é…ç½®å¥½çš„ HTTP å¤´æ˜ å°„
fn build_headers(api_key: &str) -> HeaderMap {
    let mut headers = HeaderMap::new();

    // æ·»åŠ  Bearer è®¤è¯å¤´ï¼Œç¬¦åˆ OAuth 2.0 è§„èŒƒ
    headers.insert(
        HeaderName::from_static("authorization"),
        HeaderValue::from_str(&format!("Bearer {api_key}")).unwrap(),
    );

    // æŒ‡å®šè¯·æ±‚ä½“å†…å®¹ç±»å‹ä¸º JSON
    headers.insert(
        HeaderName::from_static("content-type"),
        HeaderValue::from_static("application/json"),
    );

    headers
}

/// æ£€æŸ¥å“åº”çŠ¶æ€ç 
/// 
/// æ ¹æ® HTTP çŠ¶æ€ç è¿”å›ç›¸åº”çš„é”™è¯¯ç±»å‹
async fn check_response_status(response: reqwest::Response) -> Result<reqwest::Response> {
    let status = response.status();
    if !status.is_success() {
        let error_text = response.text().await?;
        return Err(match status.as_u16() {
            401 => NanoError::Auth(error_text),
            404 => NanoError::ModelNotFound(error_text),
            429 => NanoError::RateLimit(error_text),
            400 => NanoError::InvalidRequest(error_text),
            _ => NanoError::Api(format!("HTTP {}: {}", status, error_text)),
        });
    }
    Ok(response)
}

/// æå–å“åº”å†…å®¹çš„å®
/// 
/// ä» API å“åº”ä¸­æå–æ–‡æœ¬å†…å®¹
macro_rules! extract_content {
    ($completion:expr) => {
        $completion
            .choices
            .into_iter()
            .next()
            .map(|c| c.message.content)
            .ok_or(NanoError::NoContent)
    };
}

/// æ„å»ºè¯·æ±‚ç»Ÿè®¡ä¿¡æ¯çš„å®
/// 
/// ä» API å“åº”ä¸­æå–ç»Ÿè®¡ä¿¡æ¯
macro_rules! build_stats {
    ($completion:expr) => {
        RequestStats {
            duration_ms: 0, // ç”±è°ƒç”¨æ–¹æ ¹æ®å®é™…è¯·æ±‚è€—æ—¶è®¾ç½®
            prompt_tokens: $completion.usage.as_ref().map(|u| u.prompt_tokens),
            completion_tokens: $completion.usage.as_ref().map(|u| u.completion_tokens),
            total_tokens: $completion.usage.as_ref().map(|u| u.total_tokens),
            model: String::new(), // ç”±è°ƒç”¨æ–¹è®¾ç½®å®é™…ä½¿ç”¨çš„æ¨¡å‹åç§°
            timestamp: Some(std::time::SystemTime::now()),
        }
    };
}

/// å¤„ç†æ™®é€šå“åº”
/// 
/// è§£æ API å“åº”å¹¶æå–æ–‡æœ¬å†…å®¹
async fn handle_response(response: reqwest::Response) -> Result<String> {
    let response = check_response_status(response).await?;
    let completion: CompletionResponse = response.json().await?;
    extract_content!(completion)
}

/// å¤„ç†å¸¦ç»Ÿè®¡ä¿¡æ¯çš„å“åº”
/// 
/// è§£æ API å“åº”å¹¶æå–å†…å®¹å’Œç»Ÿè®¡ä¿¡æ¯
async fn handle_response_with_stats(response: reqwest::Response) -> Result<ResponseWithStats> {
    let response = check_response_status(response).await?;
    let completion: CompletionResponse = response.json().await?;
    let content = extract_content!(completion)?;
    let stats = build_stats!(completion);
    Ok(ResponseWithStats { content, stats })
}

/// å¤„ç†æµå¼å“åº”æ•°æ®å—
/// 
/// è§£æ SSE (Server-Sent Events) æ ¼å¼çš„æµå¼æ•°æ®
/// 
/// # å‚æ•°
/// 
/// * `text` - åŸå§‹æ–‡æœ¬æ•°æ®
/// 
/// # è¿”å›
/// 
/// æå–çš„æ–‡æœ¬å†…å®¹ç‰‡æ®µ
fn process_stream_chunk(text: &str) -> Result<String> {
    // æ£€æŸ¥æ˜¯å¦åŒ…å« SSE æ•°æ®æ ‡è®°
    if !text.contains("data: ") {
        return Ok(String::new());
    }

    // é€è¡Œå¤„ç† SSE æ•°æ®
    text.lines()
        .filter(|line| line.starts_with("data: ") && !line.contains("[DONE]"))
        .find_map(|line| {
            line.strip_prefix("data: ")
                .and_then(|json_str| serde_json::from_str::<StreamResponse>(json_str).ok())
                .and_then(|stream_data| {
                    stream_data
                        .choices
                        .into_iter()
                        .next()
                        .and_then(|c| c.delta.content)
                })
        })
        .map(Ok)
        .unwrap_or_else(|| Ok(String::new()))
}

/// åˆ›å»ºæ¶ˆæ¯çš„ä¾¿æ·å‡½æ•°
/// 
/// # å‚æ•°
/// 
/// * `role` - æ¶ˆæ¯è§’è‰²
/// * `content` - æ¶ˆæ¯å†…å®¹
/// 
/// # è¿”å›
/// 
/// æ–°åˆ›å»ºçš„æ¶ˆæ¯å®ä¾‹
/// 
/// # ç¤ºä¾‹
/// 
/// ```rust
/// use nanoai::message;
/// 
/// let msg = message("user", "Hello, world!");
/// assert_eq!(msg.role, "user");
/// assert_eq!(msg.content, "Hello, world!");
/// ```
pub fn message(role: &str, content: &str) -> Message {
    Message {
        role: role.to_string(),
        content: content.to_string(),
    }
}

// ================================================================================================
// æµ‹è¯•æ¨¡å—
// ================================================================================================

#[cfg(test)]
mod tests {
    use super::*;

    /// ç®€åŒ–é…ç½®å­—æ®µæ–­è¨€çš„å®
    macro_rules! assert_config_field {
        ($config:expr, $field:ident, $expected:expr) => {
            assert_eq!($config.$field, $expected);
        };
    }

    /// ç®€åŒ–å‚æ•°æ–­è¨€çš„å®
    macro_rules! assert_param {
        ($params:expr, $key:expr, $expected:expr) => {
            assert_eq!($params[$key], $expected);
        };
        ($params:expr, $key:expr, float, $expected:expr) => {
            let value = $params[$key].as_f64().unwrap();
            assert!((value - $expected).abs() < 0.001);
        };
    }

    #[test]
    fn test_config_default() {
        let config = Config::default();
        assert_config_field!(config, model, "tngtech/deepseek-r1t2-chimera:free");
        assert_config_field!(config, temperature, 0.7);
        assert_config_field!(config, max_tokens, 4096);
        assert_config_field!(config, random_seed, None);
    }

    #[test]
    fn test_config_builder_pattern() {
        let config = Config::default()
            .with_model("gpt-4".to_string())
            .with_api_key("test-key".to_string())
            .with_temperature(0.5)
            .with_random_seed(12345);
        assert_config_field!(config, model, "gpt-4");
        assert_config_field!(config, api_key, "test-key");
        assert_config_field!(config, temperature, 0.5);
        assert_config_field!(config, random_seed, Some(12345));
    }

    #[test]
    fn test_config_random_seed_auto() {
        let config1 = Config::default().with_random_seed_auto();
        let config2 = Config::default().with_random_seed_auto();
        assert!(config1.random_seed.is_some());
        assert!(config2.random_seed.is_some());
        assert_ne!(config1.random_seed, config2.random_seed);
    }

    #[test]
    fn test_message_creation() {
        let msg = message("user", "Hello, world!");
        assert_eq!(msg.role, "user");
        assert_eq!(msg.content, "Hello, world!");
    }

    #[test]
    fn test_prepare_messages() {
        let user_messages = vec![message("user", "Hello"), message("assistant", "Hi there!")];
        let result = prepare_messages("You are helpful", &user_messages).unwrap();
        assert_eq!(result.len(), 3);
        assert_eq!(result[0].role, "system");
        assert_eq!(result[0].content, "You are helpful");
        assert_eq!(result[1].role, "user");
        assert_eq!(result[2].role, "assistant");
    }

    #[test]
    fn test_build_params_without_seed() {
        let config = Config::default();
        let messages = vec![message("user", "test")];
        let params = build_params(&config, messages);
        assert_param!(params, "model", "tngtech/deepseek-r1t2-chimera:free");
        assert_param!(params, "stream", false);
        assert_param!(params, "max_tokens", 4096);
        assert_param!(params, "temperature", float, 0.7);
        assert!(params.get("seed").is_none());
    }

    #[test]
    fn test_build_params_with_seed() {
        let config = Config::default().with_random_seed(42);
        let messages = vec![message("user", "test")];
        let params = build_params(&config, messages);
        assert_param!(params, "seed", 42);
    }

    #[test]
    fn test_build_params_openrouter() {
        let config = Config::default().with_model("openai/gpt-4".to_string());
        let messages = vec![message("user", "test")];
        let params = build_params(&config, messages);
        assert_param!(params, "model", "openai/gpt-4");
        assert_param!(params, "max_tokens", 4096);
        assert_param!(params, "temperature", float, 0.7);
        assert_param!(params, "top_p", 1.0);
    }

    #[test]
    fn test_build_headers() {
        let headers = build_headers("test-api-key");
        assert!(headers.contains_key("authorization"));
        assert!(headers.contains_key("content-type"));
        let auth_value = headers.get("authorization").unwrap().to_str().unwrap();
        assert_eq!(auth_value, "Bearer test-api-key");
    }

    #[tokio::test]
    async fn test_llm_client_creation() {
        let config = Config::default().with_api_key("test-key".to_string());
        let client = LLMClient::new(config.clone());
        assert_config_field!(client.config, api_key, "test-key");
    }
}
